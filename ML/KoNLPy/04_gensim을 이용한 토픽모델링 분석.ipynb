{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim으로 뉴스 기사 토픽 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 기사 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 전기차업체 테슬라 주가가 질주하며 24일(현지시간) 시가총액 5000억달러(약 555조원)를 돌파했다. 테슬라 주가 급등으로 지난주 세계 3위 부자에 올랐던 일론 머스크 최고경영자(CEO)는 1주일 만에 순위를 2위로 끌어올렸다.이날 뉴욕증시에서 테슬라는 전거래일 대비 6.43% 오른 주당 555.38달러에 거래를 마치며 사상 최고가를 기록했다. 주가 527.48달러가 시총 5000억달러의 분기점이었는데, 이를 훌쩍 넘었다. 테슬라 주가는 말그대로 질주하고 있다. 코로나19 팬데믹 이전인 지난 1월22일 시총 1000억달러를 처음 넘은 이후 10개월여 만에 5배 이상 불어났다. 일부 우려에도 불구, 실적을 숫자로 보여주며 승승장구하고 있는 것. 경제전문매체 CNBC에 따르면 테슬라는 올 3분기에 창립 후 최대 규모인 13만9300대의 차량을 인도했다. 판매량 증가는 실적 호조로 이어져 올 3분기까지 5개 분기 연속 흑자를 냈다.여러 변수도 테슬라 주가의 추가 상승을 예고하고 있다. 우선, 다음달 21일 스탠더드앤드푸어스(S&P)500 지수 편입이 예정돼 있다. 이에 따른 패시브 자금 유입이 기대된다. 모건스탠리는 지난주 테슬라에 대한 투자 의견을 ‘비중 확대’로 상향 조정했다.조 바이든 미 대통령 당선인의 환경 중시 정책으로 전기차 랠리가 이어지고 있는 점도 우호적 요인이다. 전기차 대장주 테슬라가 최대 수혜주로 부각되고 있다.테슬라 목표주가를 1000달러까지 제시한 증권사도 나왔다. 미국 웨드부시증권은 최근 향후 수년간 전기차 수요가 늘 것이라며 테슬라의 목표주가를 800달러에서 1000달러로 올렸다.테슬라 주가가 급등하면서 머스크 CEO는 제프 베이조스 아마존 CEO에 이어 세계 2위 부자에 올랐다. 지난주 마크 저커버그 페이스북 CEO를 제치고 3위에 오른데 이어, 빌 게이츠 MS 창업자까지 제쳤다.\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def get_daum_news_content(news_id):\n",
    "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    \n",
    "    content = ''\n",
    "    for p in soup.select('div#harmonyContainer p'):\n",
    "        content += p.get_text()\n",
    "    return content\n",
    "\n",
    "\n",
    "news_contents = []\n",
    "news_ids = ['20190728165812603', '20201125113816419', '20201125093706258', '20201121070335100', '20201118084434035']\n",
    "\n",
    "page_contents = []\n",
    "for id in news_ids:\n",
    "    text = get_daum_news_content(id)\n",
    "    page_contents.append(text)\n",
    "\n",
    "\n",
    "news_contents.append(page_contents)\n",
    "\n",
    "print(news_contents[0][1])\n",
    "print(len(page_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/daum_news_content.pk\", \"wb\") as f:\n",
    "    pickle.dump(news_contents, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 토픽 모델링을 위한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import MeCab   # 형태소 분석기\n",
    "mecab = MeCab.Tagger()\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 텍스트 전처리 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_nouns(text):\n",
    "    nouns = []\n",
    "\n",
    "    # 원하는 TOKEN\\tPOS의 형태를 추출하는 정규표현식.\n",
    "    pattern = re.compile(\".*\\t[A-Z]+\")\n",
    "\n",
    "    # 패턴에 맞는 문자열을 추출하여 konlpy의 mecab 결과와 같아지도록 수정.\n",
    "    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "\n",
    "    # 추출한 token중에 POS가 명사 분류에 속하는 토큰만 선택.\n",
    "    for token in temp:\n",
    "        if token[1] == \"NNG\" or token[1] == \"NNP\" or token[1] == \"NNB\" or token[1] == \"NNBC\" or token[1] == \"NP\" or \\\n",
    "                token[1] == \"NR\":\n",
    "            nouns.append(token[0])\n",
    "\n",
    "    return nouns\n",
    "\n",
    "def mecab_morphs(text):\n",
    "    morphs = []\n",
    "\n",
    "    # 원하는 TOKEN\\tPOS의 형태를 추출하는 정규표현식.\n",
    "    pattern = re.compile(\".*\\t[A-Z]+\")\n",
    "\n",
    "    # 패턴에 맞는 문자열을 추출하여 konlpy의 mecab 결과와 같아지도록 수정.\n",
    "    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "\n",
    "    # 추출한 token중에 문자열만 선택.\n",
    "    for token in temp:\n",
    "        morphs.append(token[0])\n",
    "\n",
    "    return morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32de59e70724b5ba929c5bdbd5df844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Preprocessing'), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['아시아', '경제', '이민우', '기자', '머스크', '테슬라', '최고경영자', '자사', '전기', '자동차', '모델', '넷플릭스', '유튜브', '온라인', '동영상', '서비스', '탑재', '예고', '자율', '주행', '전기', '주행', '정보', '각종', '영상', '콘텐츠', '공간', '확장', '전략', '풀이', '현지', '시간', '버지', '주요', '외신', '머스크', '자신', '트위터', '계획', '자동차', '정차', '넷플릭스', '유튜브', '감상', '기능', '추가', '편안', '좌석', '서라운드', '사운드', '오디오', '영화관', '느낌', '강조', '테슬라', '콘텐츠', '방면', '확장', '이번', '처음', '지난달', '세계', '최대', '게임', '운전자', '폴아웃', '게임', '발표', '이후', '최근', '게임', '업체', '아타', '리사', '자동차', '경주', '게임', '포지션', '슈팅', '게임', '템페스트', '미사일', '커맨드', '고전', '게임', '제공', '운전대', '게임', '조작', '방식', '주차', '경우', '이번', '영상', '콘텐츠', '주행', '감상', '방안', '고려', '테슬라', '규제', '당국', '자율', '주행', '승인', '차량', '승객', '동영상', '설명', '자율', '주행', '안전', '우려', '상황', '차량', '공유', '서비스', '우버', '자율', '주행', '시범', '차량', '보행자', '충돌', '사고', '발생', '당시', '시험', '운전자', '디즈니', '동영상', '스트리밍', '서비스', '이용', '이민우', '기자']\n"
     ]
    }
   ],
   "source": [
    "def read_documents(input_file_name):\n",
    "    corpus = []\n",
    "    \n",
    "    with open(input_file_name, 'rb') as f:\n",
    "        temp_corpus = pickle.load(f)\n",
    "        \n",
    "    for page in temp_corpus:\n",
    "        corpus += page\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "def text_cleaning(docs):\n",
    "    # 한국어를 제외한 글자를 제거하는 함수.\n",
    "    for doc in docs:\n",
    "        doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)\n",
    "\n",
    "    return docs\n",
    "\n",
    "def define_stopwords(path):    \n",
    "    SW = set()\n",
    "    \n",
    "    with open(path, encoding='utf8') as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "\n",
    "    return SW\n",
    "\n",
    "def text_tokenizing(corpus, tokenizer):\n",
    "    token_corpus = []\n",
    "\n",
    "    if tokenizer == \"noun\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = mecab_nouns(corpus[n])\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "            \n",
    "    elif tokenizer == \"morph\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = mecab_morphs(corpus[n])\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "\n",
    "    elif tokenizer == \"word\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = corpus[n].split()\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "        \n",
    "    return token_corpus\n",
    "\n",
    "\n",
    "input_file_name = \"data/daum_news_content.pk\"\n",
    "documents = read_documents(input_file_name)\n",
    "\n",
    "SW = define_stopwords(\"stopwords-ko.txt\")\n",
    "cleaned_text = text_cleaning(documents)\n",
    "\n",
    "tokenized_text = text_tokenizing(cleaned_text, tokenizer=\"noun\") # tokenizer = \"noun\" or \"word\"\n",
    "\n",
    "print(tokenized_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 읽기의 과정은 앞서 단어 임베딩의 경우와 다르지 않다. 다음 과정은 문서-단어 행렬을 만드는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 토픽 모델링에 사용할 함수들 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서-단어 행렬 만들기\n",
    "# 어휘(vocabulary) 학습\n",
    "dictionary = corpora.Dictionary(tokenized_text)\n",
    "\n",
    "# 문서-단어 행렬(document-term matrix) 생성 = sklarn.count-vectorizer와 동일\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(378 unique tokens: ['각종', '감상', '강조', '게임', '경우']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 2), (2, 1), (3, 7), (4, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:5]   # (index, word-frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.07480649367196546),\n",
       " (1, 0.14961298734393091),\n",
       " (2, 0.07480649367196546),\n",
       " (3, 0.5236454557037582),\n",
       " (4, 0.023743117703705182)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF 문서-단어 행렬 생성\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "corpus_tfidf[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model\n",
    "model = models.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('테슬라', 0.023975313),\n",
       " ('보험', 0.020588325),\n",
       " ('보험료', 0.020287853),\n",
       " ('차량', 0.018366486),\n",
       " ('제시', 0.017672697),\n",
       " ('주행', 0.01587173),\n",
       " ('자율', 0.014155747),\n",
       " ('전기차', 0.014036418),\n",
       " ('소비자', 0.01108369),\n",
       " ('자동차', 0.010765007)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topic(topicid=0, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('테슬라', 0.043347653),\n",
       " ('에어컨', 0.019266868),\n",
       " ('주가', 0.018104866),\n",
       " ('달러', 0.015998453),\n",
       " ('머스크', 0.013409254),\n",
       " ('세계', 0.01090842),\n",
       " ('가정', 0.010259191),\n",
       " ('전기차', 0.008831249),\n",
       " ('에너지', 0.008336654),\n",
       " ('저커버그', 0.007808477)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topic(topicid=2, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 토픽 모델링을 추가하여 코드 완성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic ID: 0\n",
      "\t테슬라\t0.029563775286078453\n",
      "\t에어컨\t0.02186998352408409\n",
      "\t가정\t0.013844176195561886\n",
      "\t머스크\t0.01099263597279787\n",
      "\t달러\t0.010756781324744225\n",
      "\t닛케이\t0.009071593172848225\n",
      "\t에너지\t0.008136250078678131\n",
      "\t주가\t0.00780560914427042\n",
      "\t전기\t0.007796871475875378\n",
      "\t세계\t0.0076948800124228\n",
      "\t가능\t0.007597193121910095\n",
      "\t저커버그\t0.007148283533751965\n",
      "\t부자\t0.00658964179456234\n",
      "\t제휴\t0.006577902007848024\n",
      "\t생산\t0.006550389342010021\n",
      "\t차량\t0.006527837831526995\n",
      "\t절약\t0.006504897028207779\n",
      "\t재산\t0.006036144215613604\n",
      "\t지수\t0.005630275700241327\n",
      "\t설명\t0.005564847029745579\n",
      "\t게임\t0.005531303118914366\n",
      "\t효율\t0.005472053773701191\n",
      "\t자동차\t0.005287159699946642\n",
      "\t자율\t0.005266539286822081\n",
      "\t만큼\t0.005227029789239168\n",
      "\t일반\t0.005191377829760313\n",
      "\t전기차\t0.004932462703436613\n",
      "\t주행\t0.004928546492010355\n",
      "\t시작\t0.004891617223620415\n",
      "\t배터리\t0.004850378260016441\n",
      "\n",
      "\n",
      "Topic ID: 1\n",
      "\t테슬라\t0.031250324100255966\n",
      "\t주가\t0.021136265248060226\n",
      "\t달러\t0.01895815320312977\n",
      "\t게임\t0.013170955702662468\n",
      "\t주행\t0.01134065818041563\n",
      "\t머스크\t0.009518957696855068\n",
      "\t전기차\t0.008369664661586285\n",
      "\t분기\t0.008300184272229671\n",
      "\t차량\t0.008201655931770802\n",
      "\t세계\t0.007642981130629778\n",
      "\t자율\t0.0070594483986496925\n",
      "\t자동차\t0.006971102207899094\n",
      "\t콘텐츠\t0.0069307549856603146\n",
      "\t전기\t0.006835669744759798\n",
      "\t동영상\t0.006675853859633207\n",
      "\t지난주\t0.006547810975462198\n",
      "\t실적\t0.006425763946026564\n",
      "\t서비스\t0.006320145912468433\n",
      "\t최대\t0.005930913612246513\n",
      "\t급등\t0.005857141222804785\n",
      "\t시간\t0.005792594514787197\n",
      "\t업체\t0.005643527023494244\n",
      "\t부자\t0.005642028991132975\n",
      "\t경제\t0.005490761250257492\n",
      "\t기자\t0.005207394249737263\n",
      "\t최근\t0.0051961662247776985\n",
      "\t현지\t0.005121933296322823\n",
      "\t미국\t0.005051587242633104\n",
      "\t영상\t0.0049860719591379166\n",
      "\t목표\t0.004979735240340233\n",
      "\n",
      "\n",
      "Topic ID: 2\n",
      "\t테슬라\t0.034660592675209045\n",
      "\t주가\t0.014326854608952999\n",
      "\t달러\t0.014152346178889275\n",
      "\t에어컨\t0.013034743256866932\n",
      "\t전기차\t0.012330605648458004\n",
      "\t보험\t0.012243500910699368\n",
      "\t보험료\t0.01196444220840931\n",
      "\t차량\t0.011525573208928108\n",
      "\t제시\t0.01119405310600996\n",
      "\t주행\t0.010241417214274406\n",
      "\t자율\t0.008844105526804924\n",
      "\t머스크\t0.008014382794499397\n",
      "\t상승\t0.007238416001200676\n",
      "\t가능\t0.007219656836241484\n",
      "\t소비자\t0.00721299322322011\n",
      "\t설명\t0.007079140283167362\n",
      "\t분기\t0.006956719793379307\n",
      "\t관련\t0.006797336973249912\n",
      "\t자동차\t0.006786706857383251\n",
      "\t기자\t0.006766919046640396\n",
      "\t기술력\t0.00645953556522727\n",
      "\t업체\t0.006458908319473267\n",
      "\t제조사\t0.0062255049124360085\n",
      "\t전기\t0.005429680924862623\n",
      "\t사업\t0.005389699246734381\n",
      "\t시간\t0.005266526248306036\n",
      "\t가정\t0.005265902262181044\n",
      "\t사고\t0.005226599983870983\n",
      "\t분석\t0.005203485954552889\n",
      "\t급등\t0.005068045109510422\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 3\n",
    "NUM_TOPIC_WORDS = 30\n",
    "\n",
    "def build_doc_term_mat(documents):\n",
    "    # 문서-단어 행렬 만들어주는 함수.\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "    corpus = [dictionary.doc2bow(document) for document in documents]\n",
    "        \n",
    "    return corpus, dictionary\n",
    "\n",
    "\n",
    "def print_topic_words(model):\n",
    "    # 토픽 모델링 결과를 출력해 주는 함수.\n",
    "    for topic_id in range(model.num_topics):\n",
    "        topic_word_probs = model.show_topic(topic_id, NUM_TOPIC_WORDS)\n",
    "        \n",
    "        print(\"Topic ID: {}\".format(topic_id))\n",
    "        for topic_word, prob in topic_word_probs:\n",
    "            print(\"\\t{}\\t{}\".format(topic_word, prob))\n",
    "            \n",
    "        print(\"\\n\")\n",
    "\n",
    "        \n",
    "# document-term matrix를 만들고,\n",
    "corpus, dictionary = build_doc_term_mat(tokenized_text)\n",
    "\n",
    "# LDA를 실행.\n",
    "model = models.ldamodel.LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, alpha=\"auto\", eta=\"auto\")\n",
    "\n",
    "# 결과를 출력.\n",
    "print_topic_words(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. pyLDAvis를 통한 토픽 모델링 결과 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis를 jupyter notebook에서 실행할 수 있게 활성화.\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "data = pyLDAvis.gensim.prepare(model, corpus, dictionary)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LDA](./data/text_LDA.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/woosa7/nbcc_on_campus/blob/main/ML/KoNLPy/data/text_LDA.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_metadata": {
   "author": "이기황",
   "coursetitle": "텍스트분석기법",
   "courseyear": "2018",
   "date": "2018.04.18",
   "logofile": "figs/ewhauniv-logo.png",
   "logoraise": "-.2",
   "logoscale": ".4",
   "title": "단어 임베딩과 토픽 모델링"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
