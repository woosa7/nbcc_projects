{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention 신경망 구현 및 학습 - need remind ! (Part 4 Lec 58-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 2000\n",
    "MAX_LEN = 64     # 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = 'dataset/chatbot_data.csv' # acquired from 'http://www.aihub.or.kr' and modified\n",
    "okt = Okt()\n",
    "\n",
    "with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    seq = [' '.join(okt.morphs(line)) for line in lines]   # morphs : 형태소 분석\n",
    "\n",
    "questions = seq[::2]                               # 질문 : 홀수행\n",
    "answers = ['\\t ' + lines for lines in seq[1::2]]   # 답변 : 짝수행. tab = sos.\n",
    "\n",
    "num_sample = len(questions)\n",
    "num_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "perm = list(range(num_sample))\n",
    "random.seed(0)\n",
    "random.shuffle(perm)\n",
    "\n",
    "train_q = list()\n",
    "train_a = list()\n",
    "test_q = list()\n",
    "test_a = list()\n",
    "\n",
    "for idx, qna in enumerate(zip(questions, answers)):\n",
    "    q, a = qna\n",
    "    if perm[idx] > num_sample//5:  # train : 4/5\n",
    "        train_q.append(q)\n",
    "        train_a.append(a)\n",
    "    else:\n",
    "        test_q.append(q)\n",
    "        test_a.append(a)\n",
    "        \n",
    "print(len(train_q))\n",
    "print(len(test_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS,\n",
    "                                                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "tokenizer.fit_on_texts(train_q + train_a)\n",
    "\n",
    "train_q_seq = tokenizer.texts_to_sequences(train_q)\n",
    "train_a_seq = tokenizer.texts_to_sequences(train_a)\n",
    "\n",
    "test_q_seq = tokenizer.texts_to_sequences(test_q)\n",
    "test_a_seq = tokenizer.texts_to_sequences(test_a)\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(train_q_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=64)\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(train_a_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',  # !!!\n",
    "                                                        maxlen=65)       # sos, eos 포함된 길이\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(test_q_seq,\n",
    "                                                       value=0,\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=64)\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(test_a_seq,\n",
    "                                                       value=0,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=65)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(1).prefetch(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, MAX_LEN)\n",
    "        self.lstm = tf.keras.layers.LSTM(512, return_state=True)\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.emb(x)\n",
    "        _, h, c = self.lstm(x)   # hidden state, cell state\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, MAX_LEN)\n",
    "        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(NUM_WORDS, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        x, h, c = inputs\n",
    "        x = self.emb(x)\n",
    "        x, h, c = self.lstm(x, initial_state=[h, c])   # encoder에서 받은 것을 initial_state로 넣어줌\n",
    "        \n",
    "        return self.dense(x), h, c    # test 모드를 위해 h, c 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(tf.keras.Model):\n",
    "    def __init__(self, sos, eos):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        \n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "        self.sos = sos       # start of sequence\n",
    "        self.eos = eos       # end\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        if training is True:\n",
    "            x, y = inputs                 # y : shifted output\n",
    "            \n",
    "            print('x:', x.shape)\n",
    "            print(x[0])\n",
    "            print('y:', y.shape)\n",
    "            print(y[0])\n",
    "            \n",
    "            h, c = self.enc(x)            # hidden state, cell state\n",
    "\n",
    "            print('h:', h.shape)\n",
    "            print('c:', c.shape)\n",
    "\n",
    "            y, _, _ = self.dec((y, h, c)) \n",
    "            \n",
    "            print('y__:', y.shape)\n",
    "            print()\n",
    "            \n",
    "            return y\n",
    "        \n",
    "        else:               # test - 한 문장씩 테스트.\n",
    "            x = inputs\n",
    "            h, c = self.enc(x)\n",
    "            \n",
    "            # 첫번째 입력은 sos\n",
    "            y = tf.convert_to_tensor(self.sos)\n",
    "            y = tf.reshape(y, (1, 1))\n",
    "\n",
    "            seq = tf.TensorArray(tf.int32, MAX_LEN)\n",
    "\n",
    "            for idx in tf.range(MAX_LEN):\n",
    "                y, h, c = self.dec([y, h, c])  # 이전 스텝의 y, h, c를 입력으로 받음\n",
    "                y = tf.cast(tf.argmax(y, axis=-1), dtype=tf.int32)\n",
    "                y = tf.reshape(y, (1, 1))\n",
    "                seq = seq.write(idx, y)\n",
    "\n",
    "                if y == self.eos:\n",
    "                    break\n",
    "\n",
    "            return tf.reshape(seq.stack(), (1, MAX_LEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습, 테스트 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    \n",
    "    output_labels = labels[:, 1:]\n",
    "    shifted_labels = labels[:, :-1]   # 학습시 입력으로 사용\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model([inputs, shifted_labels], training=True)\n",
    "        loss = loss_object(output_labels, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(output_labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, inputs):\n",
    "    return model(inputs, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 환경 정의\n",
    "### 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Seq2seq(sos=tokenizer.word_index['\\t'],\n",
    "                eos=tokenizer.word_index['\\n'])\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define performance metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 루프 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (32, 64)\n",
      "y: (32, 64)\n",
      "h: (32, 512)\n",
      "c: (32, 512)\n",
      "y__: (32, 64, 2000)\n",
      "x: (32, 64)\n",
      "y: (32, 64)\n",
      "h: (32, 512)\n",
      "c: (32, 512)\n",
      "y__: (32, 64, 2000)\n",
      "x: (15, 64)\n",
      "y: (15, 64)\n",
      "h: (15, 512)\n",
      "c: (15, 512)\n",
      "y__: (15, 64, 2000)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "    if (epoch + 1)%10 == 0:\n",
    "        template = 'Epoch {}, Loss: {:.5f}, Accuracy: {:.5f}'\n",
    "        print(template.format(epoch + 1,\n",
    "                              train_loss.result(),\n",
    "                              train_accuracy.result()))\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "q:  ['여기 기프티콘 되죠 \\n']\n",
      "a:  ['\\t 네 현금영수증 해드릴까 요 \\n']\n",
      "p:  ['여기 서 드실 건가 요 \\n']\n",
      "_\n",
      "q:  ['네 에 테이크 아웃 도 가능한가요 \\n']\n",
      "a:  ['\\t 네 로 오시 면 테이크 아웃 잔 에 담아 드려요 \\n']\n",
      "p:  ['네 고객 님 포인트 적립 하시겠어요 \\n']\n",
      "_\n",
      "q:  ['아메리카노 톨 사이즈 로 주세요 \\n']\n",
      "a:  ['\\t 따뜻한 거 로 드릴 까요 \\n']\n",
      "p:  ['다른 사항 은 없으신 가요 \\n']\n",
      "_\n",
      "q:  ['진동 을 따로 주시나요 \\n']\n",
      "a:  ['\\t 주 번호 로 드리겠습니다 \\n']\n",
      "p:  ['네 준비 해드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['자리 있나요 \\n']\n",
      "a:  ['\\t 네 있습니다 \\n']\n",
      "p:  ['네 일회용 컵 에 담아 드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['그럼 루이보스 밀크 티 하나 \\n']\n",
      "a:  ['\\t 네 알겠습니다 \\n']\n",
      "p:  ['플랫 화이트 는 카페라테 보다 우유 양 이 좀 적게 들어갔어요 \\n']\n",
      "_\n",
      "q:  ['다음 에 무료 로 하고 엔 도장 찍어주세요 \\n']\n",
      "a:  ['\\t 네 \\n']\n",
      "p:  ['네 이리 주세요 \\n']\n",
      "_\n",
      "q:  ['아메리카노 한 잔 에 얼마 죠 \\n']\n",
      "a:  ['\\t 입니다 \\n']\n",
      "p:  ['5000원 입니다 \\n']\n",
      "_\n",
      "q:  ['얼마나 \\n']\n",
      "a:  ['\\t 바로 만들어 드릴게요 \\n']\n",
      "p:  ['네 고객 님 결제 완료 되었습니다 \\n']\n",
      "_\n",
      "q:  ['카푸치노 는 로 주시 고 아메리카노 는 로 \\n']\n",
      "a:  ['\\t 네 더 없으세요 \\n']\n",
      "p:  ['드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['아메리카노 는 어떤 종류 가 있나요 \\n']\n",
      "a:  ['\\t 디카 페인 과 기본 아메리카노 2 종류 있습니다 \\n']\n",
      "p:  ['네 저기 서 직접 가져오시면 됩니다 \\n']\n",
      "_\n",
      "q:  ['카카오 페이 로 결제 가능한가요 \\n']\n",
      "a:  ['\\t 네 가능합니다 \\n']\n",
      "p:  ['네 그럼 바로 준비 해드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['오늘 의 커피 는 커피 로 하나요 맛 이 \\n']\n",
      "a:  ['\\t 아 네 오늘 은 과테말라 커피 입니다 \\n']\n",
      "p:  ['네 이리 주세요 \\n']\n",
      "_\n",
      "q:  ['머핀 은 뭐 가 제일 \\n']\n",
      "a:  ['\\t 블루베리 머핀 이 잘 나갑니다 \\n']\n",
      "p:  ['분당선 압구정 로데오 역 을 이용 하시면 됩니다 \\n']\n",
      "_\n",
      "q:  ['현금 영수증 해주세요 \\n']\n",
      "a:  ['\\t 네 번호 찍어주세요 \\n']\n",
      "p:  ['네 번호 찍어주세요 \\n']\n",
      "_\n",
      "q:  ['둘 다 톨 사이즈 로 주세요 \\n']\n",
      "a:  ['\\t 여기 서 드시고 요 \\n']\n",
      "p:  ['할인 카드 있으신 가요 \\n']\n",
      "_\n",
      "q:  ['아이스 아메리카노 한 잔 가능한가요 \\n']\n",
      "a:  ['\\t 네 가능합니다 \\n']\n",
      "p:  ['아뇨 매장 에서는 머그컵 만 사용 가능합니다 \\n']\n",
      "_\n",
      "q:  ['아이스 아메리카노 에 샷 이 몇 개 \\n']\n",
      "a:  ['\\t 아이스 아메리카노 에 샷 은 개 \\n']\n",
      "p:  ['네 따로 추가 하실 건 없으신 가요 \\n']\n",
      "_\n",
      "q:  ['카페라테 한 잔 주세요 \\n']\n",
      "a:  ['\\t 카페라테 따뜻한 걸 로 드릴 까요 \\n']\n",
      "p:  ['네 카페라떼 컵 사이즈 는 뭘 로 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['아니요 \\n']\n",
      "a:  ['\\t 네 더 필요하신 건 없으신 가요 \\n']\n",
      "p:  ['드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['네 찍어주세요 \\n']\n",
      "a:  ['\\t 네 주문 딸기 스무디 와 쿠키 드릴게요 \\n']\n",
      "p:  ['아메리카노 티라미슈 세트 가격 은 만 원 입니다 \\n']\n",
      "_\n",
      "q:  ['시즌 메뉴 오늘 도 가능한가요 \\n']\n",
      "a:  ['\\t 네 시즌 메뉴 가능합니다 \\n']\n",
      "p:  ['500 원 입니다 \\n']\n",
      "_\n",
      "q:  ['시즌 메뉴 와 함께 되어 있는 세트 메뉴 가 있나요 \\n']\n",
      "a:  ['\\t 네 치즈 케이크 와 시즌 메뉴 두 잔 으로 세트 메뉴 있습니다 \\n']\n",
      "p:  ['네 500원 할인 되세요 \\n']\n",
      "_\n",
      "q:  ['라테 에 우유 두 도 변경 가능한가요 \\n']\n",
      "a:  ['\\t 네 라테 에 두유 로 변경 가능합니다 \\n']\n",
      "p:  ['네 500원 할인 되세요 \\n']\n",
      "_\n",
      "q:  ['네 먹고 갈 거 예요 \\n']\n",
      "a:  ['\\t 카드 여기 주세요 \\n']\n",
      "p:  ['포크 는 몇 개 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['카페인 이 음료 있나요 \\n']\n",
      "a:  ['\\t 티 음료 와 스무디 에는 카페인 이 않습니다 \\n']\n",
      "p:  ['네 500원 추가 하시면 추가 돼요 \\n']\n",
      "_\n",
      "q:  ['딸기스무디 랑 키위 스무디 는 생 과일 인가요 \\n']\n",
      "a:  ['\\t 딸기 는 키위 는 생 과일 을 사용 하고 있습니다 \\n']\n",
      "p:  ['더 필요한 건 없으시고요 \\n']\n",
      "_\n",
      "q:  ['그럼 딸기 스무디 하나 주세요 \\n']\n",
      "a:  ['\\t 드시고 가시나요 \\n']\n",
      "p:  ['추가 하시는 건 없으시고요 \\n']\n",
      "_\n",
      "q:  ['아메리카노 한 잔이요 \\n']\n",
      "a:  ['\\t 아이스 아메리카노 로 드릴 까요 \\n']\n",
      "p:  ['따뜻한 것 과 아이스 중 에 무엇 을 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['네 도 같이 \\n']\n",
      "a:  ['\\t 네 아메리카노 4000원 입니다 \\n']\n",
      "p:  ['휘핑크림 올려 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['디카 페인 아이스 아메리카노 한 잔 주세요 \\n']\n",
      "a:  ['\\t 디카 페인 아이스 아메리카노 는 기존 금액 에 300원 추가 되는데 괜찮으신 가요 \\n']\n",
      "p:  ['네 총 8000원 입니다 \\n']\n",
      "_\n",
      "q:  ['커피 음료 것 뭐 가 있나요 \\n']\n",
      "a:  ['\\t 스무디 와 주스 있습니다 \\n']\n",
      "p:  ['네 가능합니다 \\n']\n",
      "_\n",
      "q:  ['주스 어떤 종류 있나요 \\n']\n",
      "a:  ['\\t 딸기 주스 주스 주스 가 있습니다 \\n']\n",
      "p:  ['어니언 크림 이랑 플레인 크림 있습니다 \\n']\n",
      "_\n",
      "q:  ['플랫 화이트 라지 로 주세요 \\n']\n",
      "a:  ['\\t 네 \\n']\n",
      "p:  ['드시고 가실 건가 요 \\n']\n",
      "_\n",
      "q:  ['네 레드 벨벳 케이크 주세요 \\n']\n",
      "a:  ['\\t 음료 는 뭘 로 드릴 까요 \\n']\n",
      "p:  ['드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['네 먹고 갈 거 예요 \\n']\n",
      "a:  ['\\t 유리잔 괜찮으세요 \\n']\n",
      "p:  ['포크 는 몇 개 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['따뜻한 밀크 티 주세요 \\n']\n",
      "a:  ['\\t 네 \\n']\n",
      "p:  ['사이즈 는 어떻게 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['음료 얼마나 하나요 \\n']\n",
      "a:  ['\\t 10분 정도 주시 면 됩니다 \\n']\n",
      "p:  ['따뜻한 거 맞으세요 \\n']\n",
      "_\n",
      "q:  ['아이스 아메리카노 한잔 얼마 인가요 \\n']\n",
      "a:  ['\\t 4500원 입니다 \\n']\n",
      "p:  ['2000원 입니다 \\n']\n",
      "_\n",
      "q:  ['현금영수증 번호 \\n']\n",
      "a:  ['\\t 네 \\n']\n",
      "p:  ['네 이리 주세요 \\n']\n",
      "_\n",
      "q:  ['이 카드 로 결제 해주세요 \\n']\n",
      "a:  ['\\t 네 결제 도 와 드릴게요 \\n']\n",
      "p:  ['네 결제 해드렸습니다 \\n']\n",
      "_\n",
      "q:  ['주문 한 게 다 안 \\n']\n",
      "a:  ['\\t 주 번호 가 몇 이 죠 \\n']\n",
      "p:  ['네 더 필요하신 건 없으세요 \\n']\n",
      "_\n",
      "q:  ['을 \\n']\n",
      "a:  ['\\t \\n']\n",
      "p:  ['6700원 결제 도 와 드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['베이글 은 얼마 인가요 \\n']\n",
      "a:  ['\\t 베이글 은 2000원 입니다 \\n']\n",
      "p:  ['베이글 크림 은 어떤 걸 로 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['지금 되나요 \\n']\n",
      "a:  ['\\t 는 계절 메뉴 라 지금 은 판매 하지 않습니다 \\n']\n",
      "p:  ['네 포인트 사용 하시면 있습니다 \\n']\n",
      "_\n",
      "q:  ['바닐라 라테 는 따뜻하게 주세요 \\n']\n",
      "a:  ['\\t 네 적립 이나 할인 카드 있으세요 \\n']\n",
      "p:  ['사이즈 는 어떻게 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['테이크 아웃 으로 부탁드립니다 \\n']\n",
      "a:  ['\\t 결제 는 이 쪽 에서 도 와 드릴게요 \\n']\n",
      "p:  ['네 진동 벨 울리면 픽업 테이블 로 와주세요 \\n']\n",
      "_\n",
      "q:  ['혹시 테이크 아웃 잔 에 수 있나요 \\n']\n",
      "a:  ['\\t 테이크 아웃 하시는 건가 요 \\n']\n",
      "p:  ['헤이즐넛 시럽 은 500원 추가 됩니다 \\n']\n",
      "_\n",
      "q:  ['아메리카노 하나 는 샷 추가 해주세요 \\n']\n",
      "a:  ['\\t 아메리카노 는 둘 다 따뜻한 걸 로 드릴 까요 \\n']\n",
      "p:  ['아이스 아메리카노 4000원 입니다 \\n']\n",
      "_\n",
      "q:  ['쿠폰 찍어주세요 \\n']\n",
      "a:  ['\\t 네 찍어 드릴게요 \\n']\n",
      "p:  ['아메리카노 티라미슈 세트 가격 은 만 원 입니다 \\n']\n",
      "_\n",
      "q:  ['주문 할게요 \\n']\n",
      "a:  ['\\t 어떤 거 드릴 까요 \\n']\n",
      "p:  ['네 아이스 아메리카노 로 한 잔 드릴게요 \\n']\n",
      "_\n",
      "q:  ['파나요 \\n']\n",
      "a:  ['\\t 는 계절 지금 은 \\n']\n",
      "p:  ['네 계산 해드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['그럼 겨울 메뉴 뭐 가 \\n']\n",
      "a:  ['\\t 겨울 엔 감귤 라테 가 제일 많이 나가요 \\n']\n",
      "p:  ['네 다른 필요하신 건 없으세요 \\n']\n",
      "_\n",
      "q:  ['네 결제 는 카드 로 할게요 \\n']\n",
      "a:  ['\\t 네 결제 완료 되었습니다 \\n']\n",
      "p:  ['네 감사합니다 \\n']\n",
      "_\n",
      "q:  ['둘 다 사이즈 로 할게요 \\n']\n",
      "a:  ['\\t 네 결제 는 어떤 것 으로 도 와 드릴 까요 \\n']\n",
      "p:  ['아메리카노 뜨거운건 가요 \\n']\n",
      "_\n",
      "q:  ['기프티콘 으로 결제 할게요 \\n']\n",
      "a:  ['\\t 네 그럼 쿠폰 저 \\n']\n",
      "p:  ['네 카드 받았습니다 \\n']\n",
      "_\n",
      "q:  ['녹차 라테 1 잔 주세요 \\n']\n",
      "a:  ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n",
      "p:  ['휘핑크림 올려 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['네 그럼 휘핑크림 추가 해서 주세요 \\n']\n",
      "a:  ['\\t 네 녹차 라테 에 휘핑크림 추가 해서 4500원 입니다 \\n']\n",
      "p:  ['네 총 9500원 결제 해드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['브레드 종류 는 뭐 가 있나요 \\n']\n",
      "a:  ['\\t 허니 브레드 와 갈릭 치즈 브레드 가 있습니다 \\n']\n",
      "p:  ['네 500원 추가 하시면 추가 돼요 \\n']\n",
      "_\n",
      "q:  ['생크림 이 건 어떤 건가 요 \\n']\n",
      "a:  ['\\t 허니 브레드 입니다 \\n']\n",
      "p:  ['네 고객 님 결제 완료 되었습니다 \\n']\n",
      "_\n",
      "q:  ['네 그렇게 만들어 주세요 \\n']\n",
      "a:  ['\\t 더 필요한 건 없으세요 \\n']\n",
      "p:  ['쿠폰 다 맞게 오셨네요 \\n']\n",
      "_\n",
      "q:  ['여기 있습니다 \\n']\n",
      "a:  ['\\t 네 확인 되셨고 되면 진동 벨 거 예요 \\n']\n",
      "p:  ['손님 지금 15000 포인트 있으신 데 사용 해 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['핫초코 한 잔 아메리카노 사이 즈 업 한 잔 하면 얼마 인가요 \\n']\n",
      "a:  ['\\t 입니다 \\n']\n",
      "p:  ['9500원 입니다 \\n']\n",
      "_\n",
      "q:  ['주스 는 다른 건 없나요 \\n']\n",
      "a:  ['\\t 그럼 에 라테 추천 \\n']\n",
      "p:  ['네 고객 님 티 종류 다 아이스 가능합니다 \\n']\n",
      "_\n",
      "q:  ['그건 \\n']\n",
      "a:  ['\\t 네 만 따듯 해 요 \\n']\n",
      "p:  ['네 고객 님 사이즈 는 톨 사이즈 괜찮으신 가요 \\n']\n",
      "_\n",
      "q:  ['통신사 할인 되죠 \\n']\n",
      "a:  ['\\t 네 300원 할인 됩니다 \\n']\n",
      "p:  ['아메리카노 티라미슈 세트 가격 은 만 원 입니다 \\n']\n",
      "_\n",
      "q:  ['매장 에서 언제 까지 영업 하시나요 \\n']\n",
      "a:  ['\\t 오후 10시 까지 영업 입니다 \\n']\n",
      "p:  ['네 또 더 필요한 거 있으세요 \\n']\n",
      "_\n",
      "q:  ['아니요 그냥 주세요 \\n']\n",
      "a:  ['\\t 결제 해드릴게요 \\n']\n",
      "p:  ['카페모카 5천 원 입니다 \\n']\n",
      "_\n",
      "q:  ['가격 안 되나요 \\n']\n",
      "a:  ['\\t 한 해드릴게요 \\n']\n",
      "p:  ['네 가능합니다 \\n']\n",
      "_\n",
      "q:  ['카페라테 한잔 주세요 \\n']\n",
      "a:  ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n",
      "p:  ['드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['네 차가운 걸 로 주세요 \\n']\n",
      "a:  ['\\t 4500원 입니다 \\n']\n",
      "p:  ['드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['어떤 게 괜찮아요 \\n']\n",
      "a:  ['\\t 이나 원두 를 하시는 게 아니면 예 가체 많이 추천 \\n']\n",
      "p:  ['화장실 은 복도 로 나가시 면 보여요 \\n']\n",
      "_\n",
      "q:  ['그럼 추천 치즈 케이크 도 같이 주세요 \\n']\n",
      "a:  ['\\t 네 매장 에서 드시고 가시나요 \\n']\n",
      "p:  ['네 따로 추가 하실 건 없으신 가요 \\n']\n",
      "_\n",
      "q:  ['그리고 휘핑크림 은 에스프레소 크림 으로 \\n']\n",
      "a:  ['\\t 결제 는 어떻게 해드릴까 요 \\n']\n",
      "p:  ['베이글 크림 은 어떤 걸 로 알려 드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['지금 도 할인 하나요 \\n']\n",
      "a:  ['\\t 네 10시 까지 하고 있습니다 \\n']\n",
      "p:  ['11시 까지 합니다 \\n']\n",
      "_\n",
      "q:  ['그럼 와 아이스 아메리카노 로 할게요 \\n']\n",
      "a:  ['\\t 더 필요하신 건 없나요 \\n']\n",
      "p:  ['네 총 나 티 는 블랙 티 아이스 로 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['네 할인 적립 은 \\n']\n",
      "a:  ['\\t 네 바코드 \\n']\n",
      "p:  ['쿠폰 다 맞게 오셨네요 \\n']\n",
      "_\n",
      "q:  ['초코 프라푸치노 주세요 \\n']\n",
      "a:  ['\\t 휘핑 올려 드릴 까요 \\n']\n",
      "p:  ['추가 하실 건 없으세요 \\n']\n",
      "_\n",
      "q:  ['시럽 도 가 \\n']\n",
      "a:  ['\\t 드시고 가시나요 \\n']\n",
      "p:  ['네 고객 님 사이즈 는 뭘 로 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['둘 다 사이즈 로 주세요 \\n']\n",
      "a:  ['\\t 드시고 가시나요 \\n']\n",
      "p:  ['다른 건 필요 없으신 가요 \\n']\n",
      "_\n",
      "q:  ['마시다가 갈 건데 테이크아웃 으로 주세요 \\n']\n",
      "a:  ['\\t 상 매장 에서는 머그컵 으로 드리고 있어요 \\n']\n",
      "p:  ['상큼 한 블루베리 좋아하시는 분 들 도 아이스 로 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['나갈 때 테이크아웃 컵 으로 수 있나요 \\n']\n",
      "a:  ['\\t 네 그렇게 해드릴게요 \\n']\n",
      "p:  ['네 합쳐 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['아메리카노 두 잔 한잔 주세요 \\n']\n",
      "a:  ['\\t 드시고 가실 건가 요 \\n']\n",
      "p:  ['드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['얼마나 하나요 \\n']\n",
      "a:  ['\\t 5분 정도 \\n']\n",
      "p:  ['10분 정도 걸려요 \\n']\n",
      "_\n",
      "q:  ['포인트 적립 해주세요 \\n']\n",
      "a:  ['\\t 네 번호 입력 부탁드립니다 \\n']\n",
      "p:  ['네 알겠습니다 \\n']\n",
      "_\n",
      "q:  ['네 번호 로 할게요 \\n']\n",
      "a:  ['\\t 네 에 번호 \\n']\n",
      "p:  ['네 진동 벨 울리면 찾으러 오세요 \\n']\n",
      "_\n",
      "q:  ['아 포인트 포인트 사용 해주세요 \\n']\n",
      "a:  ['\\t 네 고객 님 포인트 총 있으신 데 사용 도 와 드리겠습니다 \\n']\n",
      "p:  ['알겠습니다 \\n']\n",
      "_\n",
      "q:  ['톨 사이즈 로 주문 할게요 \\n']\n",
      "a:  ['\\t 네 계산 도 와 드리겠습니다 \\n']\n",
      "p:  ['네 어떤 걸 로 하시겠습니까 \\n']\n",
      "_\n",
      "q:  ['아메리카노 사이즈 가능한가요 \\n']\n",
      "a:  ['\\t 네 500원 만 추가 하시면 가능하십니다 \\n']\n",
      "p:  ['네 가능합니다 \\n']\n",
      "_\n",
      "q:  ['사이 즈 업 해서 주세요 \\n']\n",
      "a:  ['\\t 네 결제 는 어떻게 도 와 드릴 까요 \\n']\n",
      "p:  ['네 사이즈 는 어떻게 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['커피 는 텀블러 에 담아주세요 \\n']\n",
      "a:  ['\\t 네 텀블러 할인 4000원 결제 도 와 드리겠습니다 \\n']\n",
      "p:  ['텀블러 할인 300원 같이 해드릴게요 \\n']\n",
      "_\n",
      "q:  ['아니요 아이스 로 주세요 \\n']\n",
      "a:  ['\\t 드시고 가실 건가 요 \\n']\n",
      "p:  ['네 드시고 가시나요 \\n']\n",
      "_\n",
      "q:  ['테이크아웃 할게요 \\n']\n",
      "a:  ['\\t 지금 중 인데 케이크 주문 하시면 아메리카노 한잔 로 드려요 \\n']\n",
      "p:  ['네 멤버십 카드 주시 면 도 와 드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['현금 결제 가 안 \\n']\n",
      "a:  ['\\t 현금 은 에서 주문 도 와 드리겠습니다 \\n']\n",
      "p:  ['사이즈 는 어떻게 드릴 까요 \\n']\n",
      "_\n",
      "q:  ['포인트 적립 되나요 \\n']\n",
      "a:  ['\\t 번호 포인트 적립 도 와 드리고 있어요 \\n']\n",
      "p:  ['네 그럼요 \\n']\n",
      "_\n",
      "q:  ['포인트 적립 할게요 \\n']\n",
      "a:  ['\\t 네 결제 되셨습니다 \\n']\n",
      "p:  ['네 이리 주세요 \\n']\n",
      "_\n",
      "q:  ['티라미수 는 있나요 \\n']\n",
      "a:  ['\\t 네 티라미수 는 있습니다 \\n']\n",
      "p:  ['텀블러 할인 300원 같이 해드릴게요 \\n']\n",
      "_\n",
      "q:  ['네 현금영수증 해주세요 \\n']\n",
      "a:  ['\\t 네 드시고 가시나요 \\n']\n",
      "p:  ['네 번호 적어주세요 \\n']\n",
      "_\n",
      "q:  ['샷 추가 해주세요 \\n']\n",
      "a:  ['\\t 네 알겠습니다 \\n']\n",
      "p:  ['음료 나오면 진동 벨 로 알려 드리겠습니다 \\n']\n",
      "_\n",
      "q:  ['얼마 에요 \\n']\n",
      "a:  ['\\t 만 원 입니다 \\n']\n",
      "p:  ['플랫 화이트 4500원 입니다 \\n']\n",
      "_\n",
      "q:  ['아이스 아메리카노 랑 샌드위치 주세요 \\n']\n",
      "a:  ['\\t 10시 에 세트 할인 가능하세요 \\n']\n",
      "p:  ['아메리카노 원두 는 어떤 걸 로 할까 요 \\n']\n"
     ]
    }
   ],
   "source": [
    "for test_seq, test_labels in test_ds:\n",
    "    prediction = test_step(model, test_seq)\n",
    "    test_text = tokenizer.sequences_to_texts(test_seq.numpy())\n",
    "    gt_text = tokenizer.sequences_to_texts(test_labels.numpy())\n",
    "    texts = tokenizer.sequences_to_texts(prediction.numpy())\n",
    "    print('_')\n",
    "    print('q: ', test_text)\n",
    "    print('a: ', gt_text)\n",
    "    print('p: ', texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
