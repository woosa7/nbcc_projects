{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사 하강법을 이용한 얕은 신경망 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 생성, 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "pts = list()\n",
    "labels = list()\n",
    "center_pts = np.random.uniform(-8.0, 8.0, (10, 2))\n",
    "\n",
    "for label, center_pt in enumerate(center_pts):\n",
    "    # 10 * 100 = 1000 pts\n",
    "    for _ in range(100):\n",
    "        pts.append(center_pt + np.random.randn(*center_pt.shape))\n",
    "        labels.append(label)\n",
    "\n",
    "pts = np.stack(pts, axis=0).astype(np.float32)\n",
    "labels = np.stack(labels, axis=0)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((pts, labels)).shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(pts.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구조 정의\n",
    "### 얕은 신경망\n",
    "#### 입력 계층 : 2, 은닉 계층 : 128 (Sigmoid activation), 출력 계층 : 10 (Softmax activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.d1 = tf.keras.layers.Dense(128, input_dim=2, activation='sigmoid')\n",
    "        self.d2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "            \n",
    "    def call(self, x, training=None, mask=None):\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_metric):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables) # df(x)/dx\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_metric(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수 및 최적화 알고리즘 설정\n",
    "### CrossEntropy, Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 지표 설정\n",
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.2910615801811218, Accuracy: 89.0999984741211\n",
      "Epoch 200, Loss: 0.2622007131576538, Accuracy: 89.0\n",
      "Epoch 300, Loss: 0.26749688386917114, Accuracy: 88.80000305175781\n",
      "Epoch 400, Loss: 0.2575363516807556, Accuracy: 89.30000305175781\n",
      "Epoch 500, Loss: 0.25000008940696716, Accuracy: 89.80000305175781\n",
      "Epoch 600, Loss: 0.2632284164428711, Accuracy: 89.60000610351562\n",
      "Epoch 700, Loss: 0.24964496493339539, Accuracy: 90.10000610351562\n",
      "Epoch 800, Loss: 0.24530459940433502, Accuracy: 89.70000457763672\n",
      "Epoch 900, Loss: 0.24247904121875763, Accuracy: 90.5999984741211\n",
      "Epoch 1000, Loss: 0.2498401254415512, Accuracy: 90.5999984741211\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for x, label in train_ds:\n",
    "        train_step(model, x, label, loss_object, optimizer, train_loss, train_accuracy)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100))\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 및 학습 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('ch2_dataset.npz', inputs=pts, labels=labels)\n",
    "\n",
    "W_h, b_h = model.d1.get_weights()\n",
    "W_o, b_o = model.d2.get_weights()\n",
    "W_h = np.transpose(W_h)\n",
    "W_o = np.transpose(W_o)\n",
    "np.savez_compressed('ch2_parameters.npz',\n",
    "                    W_h=W_h,\n",
    "                    b_h=b_h,\n",
    "                    W_o=W_o,\n",
    "                    b_o=b_o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
