{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 문제 해결 (과소적합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense5 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        return self.dense5(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5201 - accuracy: 0.8117 - val_loss: 0.4448 - val_accuracy: 0.8362\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3887 - accuracy: 0.8594 - val_loss: 0.3933 - val_accuracy: 0.8529\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3563 - accuracy: 0.8687 - val_loss: 0.3777 - val_accuracy: 0.8595\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3360 - accuracy: 0.8749 - val_loss: 0.3975 - val_accuracy: 0.8607\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3184 - accuracy: 0.8821 - val_loss: 0.3737 - val_accuracy: 0.8663\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3043 - accuracy: 0.8867 - val_loss: 0.3659 - val_accuracy: 0.8682\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2934 - accuracy: 0.8906 - val_loss: 0.3522 - val_accuracy: 0.8760\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2825 - accuracy: 0.8932 - val_loss: 0.3606 - val_accuracy: 0.8751\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2744 - accuracy: 0.8972 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2697 - accuracy: 0.8991 - val_loss: 0.3548 - val_accuracy: 0.8743\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2597 - accuracy: 0.9011 - val_loss: 0.3466 - val_accuracy: 0.8773\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2549 - accuracy: 0.9038 - val_loss: 0.3591 - val_accuracy: 0.8760\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2485 - accuracy: 0.9071 - val_loss: 0.3465 - val_accuracy: 0.8791\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2429 - accuracy: 0.9081 - val_loss: 0.3614 - val_accuracy: 0.8763\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2393 - accuracy: 0.9093 - val_loss: 0.3672 - val_accuracy: 0.8762\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2352 - accuracy: 0.9104 - val_loss: 0.3813 - val_accuracy: 0.8697\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2275 - accuracy: 0.9125 - val_loss: 0.3655 - val_accuracy: 0.8799\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2245 - accuracy: 0.9135 - val_loss: 0.3633 - val_accuracy: 0.8814\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2206 - accuracy: 0.9152 - val_loss: 0.3780 - val_accuracy: 0.8830\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2153 - accuracy: 0.9174 - val_loss: 0.3870 - val_accuracy: 0.8801\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2138 - accuracy: 0.9181 - val_loss: 0.3975 - val_accuracy: 0.8781\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2099 - accuracy: 0.9191 - val_loss: 0.4268 - val_accuracy: 0.8710\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2056 - accuracy: 0.9206 - val_loss: 0.3840 - val_accuracy: 0.8806\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2017 - accuracy: 0.9224 - val_loss: 0.4285 - val_accuracy: 0.8796\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1984 - accuracy: 0.9236 - val_loss: 0.4163 - val_accuracy: 0.8820\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1970 - accuracy: 0.9242 - val_loss: 0.4302 - val_accuracy: 0.8804\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1953 - accuracy: 0.9253 - val_loss: 0.4412 - val_accuracy: 0.8769\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1908 - accuracy: 0.9264 - val_loss: 0.4202 - val_accuracy: 0.8791\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1870 - accuracy: 0.9270 - val_loss: 0.4172 - val_accuracy: 0.8786\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1876 - accuracy: 0.9276 - val_loss: 0.4393 - val_accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25dc8a3ae88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 수정 - DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_DN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel_DN, self).__init__()\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        # dense - BN - relu\n",
    "        self.dense1 = tf.keras.layers.Dense(32, use_bias=False)\n",
    "        self.batch1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.batch2 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = tf.keras.layers.Dense(32, use_bias=False)  # 32 + 32 -> 64\n",
    "        \n",
    "        self.batch3 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense3 = tf.keras.layers.Dense(64, use_bias=False)  # 64 + 64 -> 128\n",
    "        \n",
    "        self.batch4 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense4 = tf.keras.layers.Dense(128, use_bias=False)\n",
    "        \n",
    "        self.dense5 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # feature 추출\n",
    "        x = self.dense1(x)\n",
    "        x = self.batch1(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # DenseNet pre-activation\n",
    "        h = self.batch2(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense2(h)\n",
    "        x = tf.concat([x, h], axis=-1)\n",
    "        \n",
    "        h = self.batch3(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense3(h)\n",
    "        x = tf.concat([x, h], axis=-1)\n",
    "        \n",
    "        h = self.batch4(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense4(h)\n",
    "        x = tf.concat([x, h], axis=-1)\n",
    "        \n",
    "        return self.dense5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5165 - accuracy: 0.8161 - val_loss: 0.4446 - val_accuracy: 0.8444\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4043 - accuracy: 0.8549 - val_loss: 0.3984 - val_accuracy: 0.8566\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3662 - accuracy: 0.8663 - val_loss: 0.3804 - val_accuracy: 0.8610\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3463 - accuracy: 0.8723 - val_loss: 0.4391 - val_accuracy: 0.8472\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3283 - accuracy: 0.8784 - val_loss: 0.3785 - val_accuracy: 0.8625\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3186 - accuracy: 0.8826 - val_loss: 0.3614 - val_accuracy: 0.8684\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3105 - accuracy: 0.8846 - val_loss: 0.3694 - val_accuracy: 0.8689\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3006 - accuracy: 0.8882 - val_loss: 0.3478 - val_accuracy: 0.8746\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2919 - accuracy: 0.8913 - val_loss: 0.3769 - val_accuracy: 0.8641\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2846 - accuracy: 0.8939 - val_loss: 0.3515 - val_accuracy: 0.8784\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2758 - accuracy: 0.8970 - val_loss: 0.3593 - val_accuracy: 0.8767\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2696 - accuracy: 0.8985 - val_loss: 0.3465 - val_accuracy: 0.8764\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2652 - accuracy: 0.9012 - val_loss: 0.4017 - val_accuracy: 0.8614\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2608 - accuracy: 0.9033 - val_loss: 0.3551 - val_accuracy: 0.8725\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2577 - accuracy: 0.9046 - val_loss: 0.3387 - val_accuracy: 0.8842\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2531 - accuracy: 0.9049 - val_loss: 0.3537 - val_accuracy: 0.8787\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2539 - accuracy: 0.9042 - val_loss: 0.3665 - val_accuracy: 0.8737\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2474 - accuracy: 0.9068 - val_loss: 0.3460 - val_accuracy: 0.8822\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2414 - accuracy: 0.9092 - val_loss: 0.3575 - val_accuracy: 0.8768\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2402 - accuracy: 0.9095 - val_loss: 0.3542 - val_accuracy: 0.8795\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2373 - accuracy: 0.9110 - val_loss: 0.3476 - val_accuracy: 0.8823\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2364 - accuracy: 0.9118 - val_loss: 0.3607 - val_accuracy: 0.8754\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2311 - accuracy: 0.9129 - val_loss: 0.3475 - val_accuracy: 0.8806\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2275 - accuracy: 0.9151 - val_loss: 0.3472 - val_accuracy: 0.8834\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2281 - accuracy: 0.9148 - val_loss: 0.3693 - val_accuracy: 0.8799\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2244 - accuracy: 0.9156 - val_loss: 0.3511 - val_accuracy: 0.8807\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2202 - accuracy: 0.9168 - val_loss: 0.3445 - val_accuracy: 0.8803\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2188 - accuracy: 0.9180 - val_loss: 0.3495 - val_accuracy: 0.8834\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2165 - accuracy: 0.9190 - val_loss: 0.3479 - val_accuracy: 0.8848\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2176 - accuracy: 0.9177 - val_loss: 0.3622 - val_accuracy: 0.8849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25e700e7348>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel_DN()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
